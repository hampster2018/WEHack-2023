{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some basic imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the datasets\n",
    "\n",
    "dallas = pd.read_json('../Demographic/Dallas.json/Dallas.json')\n",
    "losAngeles = pd.read_json('../Demographic/Los Angeles.json/Los Angeles.json')\n",
    "philadelphia = pd.read_json('../Demographic/Philadelphia.json/Philadelphia.json')\n",
    "\n",
    "jsonDatasets = [dallas, losAngeles, philadelphia]\n",
    "\n",
    "parcelDallas = pd.read_csv('../parcelData/cleanDallas.csv')\n",
    "parcelPhiladelphia = pd.read_csv('../parcelData/cleanPhiladelphia.csv')\n",
    "parcelSocal = pd.read_csv('../parcelData/cleanSocal.csv')\n",
    "\n",
    "parcelDallas['City'] = 'Dallas'\n",
    "parcelPhiladelphia['City'] = 'Philadelpia'\n",
    "parcelSocal['City'] = 'Socal'\n",
    "\n",
    "parcelDallas['recrdareano'] = 0\n",
    "parcelDallas['saleprice'] = 179120\n",
    "parcelDallas['numstories'] = 0\n",
    "parcelDallas['taxamt'] = 0\n",
    "\n",
    "parcelSocal['saleprice'] = 634506\n",
    "parcelSocal['numstories'] = 0\n",
    "parcelSocal['taxamt'] = 0\n",
    "\n",
    "parcelCombined = pd.concat([parcelDallas, parcelPhiladelphia, parcelSocal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ll_gissqft  ll_gisacre  landval    parval    City  saleprice\n",
      "0         15916     0.36537    40000    193080  Dallas   179120.0\n",
      "1         12762     0.29297    63790    276580  Dallas   179120.0\n",
      "2          8085     0.18559    35000    147410  Dallas   179120.0\n",
      "3          7220     0.16575    25000    103660  Dallas   179120.0\n",
      "4          9004     0.20670    22500    130710  Dallas   179120.0\n",
      "..          ...         ...      ...       ...     ...        ...\n",
      "149       94676     2.17341  7358249  13717878   Socal   634506.0\n",
      "150       58397     1.34057   360519   1162088   Socal   634506.0\n",
      "151       18682     0.42886  1664640   2809080   Socal   634506.0\n",
      "152       23281     0.53445  1414008   2676515   Socal   634506.0\n",
      "153       18083     0.41512  1388758   2083135   Socal   634506.0\n",
      "\n",
      "[4121 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "parcelCombined = parcelCombined.drop(['numstories', 'taxamt', 'owner', 'owner2', 'owner3', 'mailadd', 'parcelnumb', 'qoz', 'saledate', 'zoning_description', 'structno', 'usedesc', 'zoning', 'recrdareano'], axis=1)\n",
    "print(parcelCombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ll_gissqft  ll_gisacre  landval    parval  saleprice  zone_Dallas  \\\n",
      "0         15916     0.36537    40000    193080   179120.0            1   \n",
      "1         12762     0.29297    63790    276580   179120.0            1   \n",
      "2          8085     0.18559    35000    147410   179120.0            1   \n",
      "3          7220     0.16575    25000    103660   179120.0            1   \n",
      "4          9004     0.20670    22500    130710   179120.0            1   \n",
      "..          ...         ...      ...       ...        ...          ...   \n",
      "149       94676     2.17341  7358249  13717878   634506.0            0   \n",
      "150       58397     1.34057   360519   1162088   634506.0            0   \n",
      "151       18682     0.42886  1664640   2809080   634506.0            0   \n",
      "152       23281     0.53445  1414008   2676515   634506.0            0   \n",
      "153       18083     0.41512  1388758   2083135   634506.0            0   \n",
      "\n",
      "     zone_Philadelpia  zone_Socal  \n",
      "0                   0           0  \n",
      "1                   0           0  \n",
      "2                   0           0  \n",
      "3                   0           0  \n",
      "4                   0           0  \n",
      "..                ...         ...  \n",
      "149                 0           1  \n",
      "150                 0           1  \n",
      "151                 0           1  \n",
      "152                 0           1  \n",
      "153                 0           1  \n",
      "\n",
      "[4121 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "parcelCombined = pd.get_dummies(parcelCombined, columns=['City'], prefix='zone')\n",
    "print(parcelCombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = parcelCombined.loc[:, parcelCombined.columns != 'landval']\n",
    "y = parcelCombined['landval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17914088 -0.17914211 -0.16140735 ... -0.80908496  0.89613808\n",
      "  -0.22882899]\n",
      " [ 0.1506368   0.15063555 -0.1032305  ... -0.80908496 -1.11589946\n",
      "   4.37007563]\n",
      " [-0.17933744 -0.17933589 -0.17272225 ... -0.80908496  0.89613808\n",
      "  -0.22882899]\n",
      " ...\n",
      " [-0.01614006 -0.01613925 -0.06314301 ...  1.23596414 -1.11589946\n",
      "  -0.22882899]\n",
      " [-0.14710143 -0.14710079  0.14618712 ... -0.80908496 -1.11589946\n",
      "   4.37007563]\n",
      " [-0.14293744 -0.14293452 -0.14088434 ...  1.23596414 -1.11589946\n",
      "  -0.22882899]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start putting together the neural network \n",
    "import keras_tuner\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('layers', 2, 10)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=16,\n",
    "                                            max_value=256,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mse'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 25s]\n",
      "val_mse: 1259712195242.6667\n",
      "\n",
      "Best val_mse So Far: 461284332885.3333\n",
      "Total elapsed time: 00h 04m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mse',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='model_dir',\n",
    "    project_name='House_Price_Prediction')\n",
    " \n",
    "tuner.search(X_train,y_train,batch_size=128,epochs=40,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "83/83 [==============================] - 1s 2ms/step - loss: -198634.3906 - accuracy: 0.0097\n",
      "Epoch 2/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -372030.4062 - accuracy: 0.0000e+00\n",
      "Epoch 3/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -555855.8125 - accuracy: 0.0000e+00\n",
      "Epoch 4/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -856843.1250 - accuracy: 0.0000e+00\n",
      "Epoch 5/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -1339424.6250 - accuracy: 0.0000e+00\n",
      "Epoch 6/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -2077256.3750 - accuracy: 0.0000e+00\n",
      "Epoch 7/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -3251924.5000 - accuracy: 0.0000e+00\n",
      "Epoch 8/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -4810077.5000 - accuracy: 0.0000e+00\n",
      "Epoch 9/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -6988069.5000 - accuracy: 0.0000e+00\n",
      "Epoch 10/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -9701577.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/14\n",
      "83/83 [==============================] - 0s 3ms/step - loss: -12939769.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -16540550.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -21198266.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/14\n",
      "83/83 [==============================] - 0s 2ms/step - loss: -26317182.0000 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d9a53d0f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training sets \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = pd.DataFrame()\n",
    "for dataset in jsonDatasets:\n",
    "    temp_X_train, temp_X_test, temp_Y_train, temp_Y_test = getTrainSplit(dataset)\n",
    "\n",
    "    X_train = pd.concat([X_train, temp_X_train], ignore_index=True)\n",
    "    X_test = pd.concat([X_test, temp_X_test], ignore_index=True)\n",
    "    Y_train = pd.concat([Y_train, temp_Y_train], ignore_index=True)\n",
    "    Y_test = pd.concat([Y_test, temp_Y_test], ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5757b24d6f2c087b08b5643eae717903ae0f84ab364071998fc27a01bff12666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
